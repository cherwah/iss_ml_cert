{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer # BOW\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF\n",
    "from sklearn.metrics.pairwise import cosine_similarity # Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that our NLTK resources are available. Run code below once to download NLTK resources. NLTK's '*stopwords*' is used for removing stop-words in our corpus and the '*wordnet*' dictionary is used for stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cherwah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/cherwah/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') \n",
    "nltk.download('wordnet')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE TINKERING: Bag of Words (BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in the 'docs' array represents a document in our corpus. Hence, we have 3 documents in our corpus and they will be used for Bag-Of-Words, TF-IDF and Cosine Similarity computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    'John has some cats.',\n",
    "    'Cats, being cats, eat fish.',\n",
    "    'I ate a big fish.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing for Stemming and Stop-Words removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We place the pre-processing code in a function as it will be used by Bag-of-Words, TF-IDF and Cosine Similarity. The function removes stop-words and punctuations, convert each term to lowercase and apply stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(docs):\n",
    "    docs_clean = []\n",
    "    punc = str.maketrans('', '', string.punctuation)\n",
    "    for doc in docs:\n",
    "        doc_no_punc = doc.translate(punc)\n",
    "        words = doc_no_punc.lower().split()    \n",
    "        words = [lemmatizer.lemmatize(word, 'v')\n",
    "                        for word in words if word not in stop_words]    \n",
    "        docs_clean.append(' '.join(words))\n",
    "    \n",
    "    return docs_clean\n",
    "\n",
    "docs_clean = preprocess(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at our documents after pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['john cat', 'cat cat eat fish', 'eat big fish']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NLTK's CountVectorizer, we generate our BOW feature vectors via Bag-of-Words technique. The output array shows the frequency-count of terms in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1],\n",
       "       [0, 2, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = CountVectorizer()\n",
    "\n",
    "# toarray() converts to a numpy array\n",
    "feature_vectors = bow.fit_transform(docs_clean).toarray()\n",
    "feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view our vocabulary (every unique word in our corpus is a feature) by asking for the feature names in the BOW matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['big', 'cat', 'eat', 'fish', 'john'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = bow.get_feature_names_out()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretty-print our BOW results by combining our vocabulary and feature-vectors into a Pandas' dataframe. Here, we can see the frequency-count against each term in a document much cleanly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>big</th>\n",
       "      <th>cat</th>\n",
       "      <th>eat</th>\n",
       "      <th>fish</th>\n",
       "      <th>john</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      big  cat  eat  fish  john\n",
       "doc1    0    1    0     0     1\n",
       "doc2    0    2    1     1     0\n",
       "doc3    1    0    1     1     0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(data=feature_vectors,\n",
    "                index=['doc1', 'doc2', 'doc3'],\n",
    "                columns=vocab)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE TINKERING: TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NLTK's TfidfVectorizer, we generate a feature-vector for each document in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.60534851, 0.        , 0.        , 0.79596054],\n",
       "       [0.        , 0.81649658, 0.40824829, 0.40824829, 0.        ],\n",
       "       [0.68091856, 0.        , 0.51785612, 0.51785612, 0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "feature_vectors = tfidf.fit_transform(docs_clean).toarray()\n",
    "feature_vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the unique tokens in our corpus (aka Vocabulary) by querying the feature names in TF-IDF matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['big', 'cat', 'eat', 'fish', 'john'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tfidf.get_feature_names_out()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We place our TF-IDF feature vectors in a Pandas DataFrame to visualize the data easily. Notice that for document 1, the values in its feature vector that corresponds to 'big', 'eat', and 'fish' are all zeros as document 1 does not contain such terms. In addition, note the high value of 0.816 for the term 'cat' in document 2's feature vector due to the two occurences of 'cat' in its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>big</th>\n",
       "      <th>cat</th>\n",
       "      <th>eat</th>\n",
       "      <th>fish</th>\n",
       "      <th>john</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc3</th>\n",
       "      <td>0.680919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517856</td>\n",
       "      <td>0.517856</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           big       cat       eat      fish      john\n",
       "doc1  0.000000  0.605349  0.000000  0.000000  0.795961\n",
       "doc2  0.000000  0.816497  0.408248  0.408248  0.000000\n",
       "doc3  0.680919  0.000000  0.517856  0.517856  0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=feature_vectors,\n",
    "                index=['doc1', 'doc2', 'doc3'],\n",
    "                columns=vocab)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE TINKERING: Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use 3 different query strings, stored in the 'query' array, to compare against the 3 documents in our corpus for similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\n",
    "    'cats and fish',\n",
    "    'and he',\n",
    "    'john'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we pre-process our query strings to remove stop-words and punctuations, and to apply stemming. The output shows the query-strings after pre-processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat fish', '', 'john']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_clean = preprocess(query)\n",
    "query_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then generate the TF-IDF feature-vectors for the 3 query strings using the earlier computed TF-IDF weights from our corpus. The TF-IDF weights were obtained when we perform a tfidf.fit_transform() in an early step (under section CODE TINKERING: TF-IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.70710678, 0.        , 0.70710678, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_feature_vector = tfidf.transform(query_clean).toarray()\n",
    "query_feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use a DataFrame to pretty-print our 3 query strings' TF-IDF feature vectors. Remember that each query-string's feature vector has the same dimension as the vocabulary in our corpus. Since we have 5 tokens in our vocabulary, the dimension for each query-string's feature vector is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>big</th>\n",
       "      <th>cat</th>\n",
       "      <th>eat</th>\n",
       "      <th>fish</th>\n",
       "      <th>john</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>q1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    big       cat  eat      fish  john\n",
       "q1  0.0  0.707107  0.0  0.707107   0.0\n",
       "q2  0.0  0.000000  0.0  0.000000   0.0\n",
       "q3  0.0  0.000000  0.0  0.000000   1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df = pd.DataFrame(data=query_feature_vector,\n",
    "                        index=['q1', 'q2', 'q3'],\n",
    "                        columns=vocab)\n",
    "\n",
    "query_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute Cosine Similarity of the 3 query-strings' TF-IDF feature vectors against the 3 documents in our corpus. Notice that the first query-string is most similar to 'doc2', having a cosine similarity value of 0.866. The third query-string is most similar to 'doc1', with a cosine similarity value of 0.796. However, the second query-string is not similar to any of the 3 documents as non of the words in its query-string is found in our corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>doc3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cs1</th>\n",
       "      <td>0.428046</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.36618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs3</th>\n",
       "      <td>0.795961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         doc1      doc2     doc3\n",
       "cs1  0.428046  0.866025  0.36618\n",
       "cs2  0.000000  0.000000  0.00000\n",
       "cs3  0.795961  0.000000  0.00000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = cosine_similarity(query_feature_vector, feature_vectors)\n",
    "\n",
    "cs = pd.DataFrame(data=similarity,\n",
    "                index=['cs1', 'cs2', 'cs3'],\n",
    "                columns=['doc1', 'doc2', 'doc3'])\n",
    "\n",
    "cs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d06f15350b31cd81f03731ed9df95b7246c9107dbc130fa4bad11e6a7891c2c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('python39_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
